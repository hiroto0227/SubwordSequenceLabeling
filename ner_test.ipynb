{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"./\")\n",
    "from ner.train import *\n",
    "from chem_sentencepiece.chem_sentencepiece import ChemSentencePiece\n",
    "from config import config_dics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "np.random.seed(seed_num)\n",
    "torch.manual_seed(seed_num)\n",
    "torch.cuda.manual_seed(seed_num)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache_dir': './Repository/Cache/',\n",
      " 'char_emb_dim': 30,\n",
      " 'char_hidden_dim': 100,\n",
      " 'glove_path': './Repository/GloVe/gv.d50',\n",
      " 'gpu': True,\n",
      " 'grad_clip': 0,\n",
      " 'lm_batch_size': 10,\n",
      " 'lm_dropout': 0.5,\n",
      " 'lm_epoch': 0,\n",
      " 'lm_input_path': './Repository/LargeCorpus/large_corpus_2000k.txt',\n",
      " 'lm_lr': 1,\n",
      " 'lm_model_dir': './Repository/LanguageModel/',\n",
      " 'ner_batch_size': 10,\n",
      " 'ner_dropout': 0.5,\n",
      " 'ner_epoch': 100,\n",
      " 'ner_input_dir': './Repository/Chemdner/',\n",
      " 'ner_lr': 0.01,\n",
      " 'ner_model_dir': './Repository/NERModel/',\n",
      " 'number_normalize': True,\n",
      " 'sp_path': {'SW2k': './Repository/SentencePiece/sp2000.model',\n",
      "             'SW4k': './Repository/SentencePiece/sp4000.model'},\n",
      " 'sw_emb_dim': 50,\n",
      " 'sw_hidden_dim': 100,\n",
      " 'vocab_dir': './Repository/Vocabulary/',\n",
      " 'weight_decay': 1e-05,\n",
      " 'word_emb_dim': 50,\n",
      " 'word_hidden_dim': 200}\n"
     ]
    }
   ],
   "source": [
    "args_config = \"SW2k.4k.2000k.NoLM\"\n",
    "config_dic = config_dics[\"SW2k.4k.2000k.NoLM\"]\n",
    "pprint.pprint(config_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentence piece\n",
    "sps: dict = {}\n",
    "for sp_key, sp_path in config_dic[\"sp_path\"].items():\n",
    "    sp = ChemSentencePiece()\n",
    "    sp.load(sp_path)\n",
    "    sps[sp_key] = sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/903738 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Load train data ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 903738/903738 [00:02<00:00, 313719.86it/s]\n",
      "100%|██████████| 898421/898421 [00:02<00:00, 405074.53it/s]\n",
      "100%|██████████| 776037/776037 [00:01<00:00, 403814.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "print(\"=========== Load train data ===========\")\n",
    "train_word_documents, train_label_documents = load_seq_data(os.path.join(config_dic.get(\"ner_input_dir\"), \"train.bioes\"), config_dic.get(\"number_normalize\"))\n",
    "valid_word_documents, valid_label_documents = load_seq_data(os.path.join(config_dic.get(\"ner_input_dir\"), \"valid.bioes\"), config_dic.get(\"number_normalize\"))\n",
    "test_word_documents, test_label_documents = load_seq_data(os.path.join(config_dic.get(\"ner_input_dir\"), \"test.bioes\"), config_dic.get(\"number_normalize\"))\n",
    "\n",
    "train_char_documents = [[[char for char in word] for word in document] for document in train_word_documents] # Document数 x 文字数\n",
    "valid_char_documents = [[[char for char in word] for word in document] for document in valid_word_documents]\n",
    "test_char_documents = [[[char for char in word] for word in document] for document in test_word_documents]\n",
    "\n",
    "train_sw_documents_dicts = {}\n",
    "valid_sw_documents_dicts = {}\n",
    "test_sw_documents_dicts = {}\n",
    "for sp_key, sp in sps.items():\n",
    "    train_sw_documents_dicts[sp_key] = get_sw_documents(train_word_documents, sp)\n",
    "    valid_sw_documents_dicts[sp_key] = get_sw_documents(valid_word_documents, sp)\n",
    "    test_sw_documents_dicts[sp_key] = get_sw_documents(test_word_documents, sp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Build vocabulary ===========\n"
     ]
    }
   ],
   "source": [
    "# load vocabulary\n",
    "print(\"=========== Build vocabulary ===========\")\n",
    "if os.path.exists(os.path.join(config_dic.get(\"vocab_dir\"), f\"{args_config}.word.dic\")):\n",
    "    word_dic = Dictionary.load(os.path.join(config_dic.get(\"vocab_dir\"), f\"{args_config}.word.dic\"))\n",
    "    char_dic = Dictionary.load(os.path.join(config_dic.get(\"vocab_dir\"), f\"{args_config}.char.dic\"))\n",
    "    sw_dicts = {}\n",
    "    for sp_key, sp in sps.items():\n",
    "        sw_dicts[sp_key] = Dictionary.load(os.path.join(config_dic.get(\"vocab_dir\"), f\"{args_config}.sw{sp_key}.dic\"))\n",
    "else:\n",
    "    special_token_dict = {PADDING: 0, UNKNOWN: 1, START: 2, END: 3}\n",
    "    word_dic = Dictionary()\n",
    "    word_dic.token2id = special_token_dict\n",
    "    char_dic = Dictionary()\n",
    "    char_dic.token2id = special_token_dict\n",
    "    sw_dicts = {}\n",
    "    for sp_key, sp in sps.items():\n",
    "        _dic = Dictionary()\n",
    "        _dic.token2id = special_token_dict\n",
    "        sw_dicts[sp_key] = _dic\n",
    "label_dic = Dictionary(train_label_documents)\n",
    "label_dic.patch_with_special_tokens({PADDING: 0})\n",
    "label_dic.id2token = {_id: label for label, _id in label_dic.token2id.items()}\n",
    "\n",
    "# add vocabulary\n",
    "word_dic.add_documents(train_word_documents)\n",
    "char_dic.add_documents(list(chain.from_iterable(train_char_documents)))\n",
    "for sp_key, train_sw_documents in train_sw_documents_dicts.items():\n",
    "    sw_dicts[sp_key].add_documents(train_sw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmで学習した後で、Trainデータで未知語になってしまった単語\n",
    "# train_oov_counter = Counter()\n",
    "# for document in train_word_documents:\n",
    "#     for word in document:\n",
    "#         if not word_dic.token2id.get(word):\n",
    "#             train_oov_counter[word] += 1\n",
    "# train_oov_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Load Pretrain Word Embeddings ================\n",
      "PerfectMatch: 35278, CaseMatch: 423, NotMatch: 6543.\n"
     ]
    }
   ],
   "source": [
    "# load GloVe\n",
    "if config_dic.get(\"glove_path\"):\n",
    "    print(\"============== Load Pretrain Word Embeddings ================\")\n",
    "    word2vec = load_pretrain_embeddings(config_dic.get(\"glove_path\"), emb_dim=config_dic.get(\"word_emb_dim\"))\n",
    "    pretrain_embeddings = build_pretrain_embeddings(word2vec, word_dic, emb_dim=config_dic.get(\"word_emb_dim\"))\n",
    "else:\n",
    "    pretrain_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42244\n",
      "42244\n",
      "SeqModel(\n",
      "  (word_lstm): WordLSTM(\n",
      "    (char_rep): CharRep(\n",
      "      (dropout): Dropout(p=0.5)\n",
      "      (char_embeddings): Embedding(42244, 30)\n",
      "      (char_lstm): LSTM(30, 50, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (subword_rep_list): ModuleList(\n",
      "      (0): SubwordRep(\n",
      "        (dropout): Dropout(p=0.5)\n",
      "        (embeddings): Embedding(42244, 50)\n",
      "        (lstm): LSTM(50, 50, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (1): SubwordRep(\n",
      "        (dropout): Dropout(p=0.5)\n",
      "        (embeddings): Embedding(42244, 50)\n",
      "        (lstm): LSTM(50, 50, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.5)\n",
      "    (word_embedding): Embedding(42244, 50)\n",
      "    (lstm): LSTM(350, 100, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (hidden2tag): Linear(in_features=200, out_features=8, bias=True)\n",
      "  (crf): CRF()\n",
      ")\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "seq_model = SeqModel(config_dic, len(word_dic.token2id), len(char_dic.token2id), [len(sw_dic.token2id) for sw_dic in sw_dicts.values()], len(label_dic.token2id), pretrain_embeddings)\n",
    "#seq_model.load_expanded_state_dict(torch.load(\"./Repository/LanguageModel/BaseLine.LM.lm_lr5.0.model\"))\n",
    "optimizer = torch.optim.SGD(seq_model.parameters(), lr=config_dic.get(\"ner_lr\"), weight_decay=config_dic.get(\"weight_decay\"), momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.999)\n",
    "\n",
    "print(seq_model)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100\n",
      "Learning Rate: [0.01]\n",
      "Batch: 50; Time(sec/batch): 0.2404; Loss: 7656.4614 Right: 13369.0, Total: 14661.0, Accuracy: 0.9119\n",
      "Batch: 100; Time(sec/batch): 0.2860; Loss: 7417.3423 Right: 25938.0, Total: 28618.0, Accuracy: 0.9064\n",
      "Batch: 150; Time(sec/batch): 0.3285; Loss: 8437.2373 Right: 39160.0, Total: 43400.0, Accuracy: 0.9023\n",
      "Batch: 200; Time(sec/batch): 0.2794; Loss: 21255.3750 Right: 51977.0, Total: 58102.0, Accuracy: 0.8946\n",
      "Batch: 250; Time(sec/batch): 0.2916; Loss: 9184.3809 Right: 64878.0, Total: 72275.0, Accuracy: 0.8977\n",
      "Batch: 300; Time(sec/batch): 0.2828; Loss: 8582.0781 Right: 77660.0, Total: 86333.0, Accuracy: 0.8995\n",
      "Batch: 350; Time(sec/batch): 0.2454; Loss: 7880.2236 Right: 90572.0, Total: 100531.0, Accuracy: 0.9009\n"
     ]
    }
   ],
   "source": [
    "## start training\n",
    "epoch = config_dic.get(\"ner_epoch\")\n",
    "for epoch_i in range(epoch):\n",
    "    print(\"Epoch: %s/%s\" %(epoch_i, epoch))\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Learning Rate: {lr_scheduler.get_lr()}\")\n",
    "    # shuffle\n",
    "    random_ids = list(range(len(train_word_documents)))\n",
    "    random.shuffle(random_ids)\n",
    "    \n",
    "    #####################  Batch Initialize ############################\n",
    "    total_loss, batch_ave_loss, right_token, total_token = 0, 0, 0, 0\n",
    "    batch_size = config_dic.get(\"ner_batch_size\")\n",
    "    batch_steps = len(train_word_documents) // batch_size + 1\n",
    "    seq_model.train()\n",
    "    seq_model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # # LangageModelを使用した時に重みを固定する。\n",
    "    # if epoch_i < 1 and config_dic.get(\"lm_model_dir\"):\n",
    "    #     print(\"=========== seq_model.word_lstm.eval() ============\")\n",
    "    #     seq_model.word_lstm.eval()\n",
    "    #     for param in seq_model.word_lstm.parameters():\n",
    "    #         param.requires_grad = False\n",
    "\n",
    "    for batch_i in range(batch_steps):\n",
    "        start_time = time.time()\n",
    "        batch_ids = random_ids[batch_i * batch_size: (batch_i + 1) * batch_size]\n",
    "        batch_word_documents = [train_word_documents[i] for i in batch_ids]\n",
    "        batch_label_documents = [train_label_documents[i] for i in batch_ids]\n",
    "        word_features = get_word_features(batch_word_documents, word_dic, config_dic.get(\"gpu\"))\n",
    "        char_features = get_char_features(batch_word_documents, char_dic, config_dic.get(\"gpu\"))\n",
    "        sw_features_list = []\n",
    "        for sp_key, sp in sps.items():\n",
    "            sw_features_list.append(get_sw_features(batch_word_documents, sw_dicts[sp_key], sp, config_dic.get(\"gpu\")))\n",
    "        label_features = get_label_features(batch_label_documents, label_dic, config_dic.get(\"gpu\"))\n",
    "        loss, train_tag_seq = seq_model.neg_log_likelihood_loss(word_features, char_features, sw_features_list, label_features)\n",
    "        batch_ave_loss += loss.data\n",
    "        total_loss += loss.data\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        seq_model.zero_grad()\n",
    "\n",
    "        rt, tt = predict_check(train_tag_seq, label_features.get(\"label_ids\"), word_features.get(\"masks\"))\n",
    "        right_token += rt\n",
    "        total_token += tt\n",
    "        if batch_i != 0 and batch_i % 50 == 0:\n",
    "            if batch_ave_loss > 1e8 or str(loss) == \"nan\":\n",
    "                print(\"Error: Loss Explosion (>1e8)! EXIT...\")\n",
    "                exit(1)\n",
    "            sys.stdout.flush()\n",
    "            print(f\"\"\"Batch: {batch_i}; Time(sec/batch): {time.time() - start_time:.4f}; Loss: {batch_ave_loss:.4f} Right: {right_token}, Total: {total_token}, Accuracy: {right_token / total_token:.4f}\"\"\") \n",
    "            batch_ave_loss = 0\n",
    "    print(f\"Total Loss: {total_loss}\")\n",
    "\n",
    "    ################ valid predict check #####################\n",
    "    print(\"============== Valid Evaluate ===========\")\n",
    "    true_seqs, pred_seqs = [], []\n",
    "    right_token, total_token = 0, 0\n",
    "    batch_steps = len(valid_word_documents) // batch_size + 1\n",
    "    random_ids = list(range(len(valid_word_documents)))\n",
    "    seq_model.eval()\n",
    "    for batch_i in range(batch_steps):\n",
    "        batch_ids = random_ids[batch_i * batch_size: (batch_i + 1) * batch_size]\n",
    "        batch_word_documents = [valid_word_documents[i] for i in batch_ids]\n",
    "        batch_label_documents = [valid_label_documents[i] for i in batch_ids]\n",
    "\n",
    "        valid_word_features = get_word_features(batch_word_documents, word_dic, config_dic.get(\"gpu\"))\n",
    "        valid_char_features = get_char_features(batch_word_documents, char_dic, config_dic.get(\"gpu\"))\n",
    "        valid_sw_features_list = []\n",
    "        for sp_key, sp in sps.items():\n",
    "            valid_sw_features_list.append(get_sw_features(batch_word_documents, sw_dicts[sp_key], sp, config_dic.get(\"gpu\")))\n",
    "        valid_label_features = get_label_features(batch_label_documents, label_dic, config_dic.get(\"gpu\"))\n",
    "        valid_tag_seq = seq_model.forward(valid_word_features, valid_char_features, valid_sw_features_list)\n",
    "        masks = valid_word_features.get(\"masks\")\n",
    "        rt, tt = predict_check(valid_tag_seq, valid_label_features.get(\"label_ids\"), masks)\n",
    "        right_token += rt\n",
    "        total_token += tt\n",
    "        ################ evaluate by precision, recall and fscore ###################\n",
    "        true_seqs.extend([label_dic.id2token.get(int(label_id), label_dic.token2id[\"O\"]) for label_id in valid_label_features.get(\"label_ids\").masked_select(masks)])\n",
    "        pred_seqs.extend([label_dic.id2token.get(int(label_id), label_dic.token2id[\"O\"]) for label_id in valid_tag_seq.masked_select(masks)])\n",
    "    precision, recall, fscore = evaluate(true_seqs, pred_seqs)\n",
    "    print(f\"Right: {right_token}, Total: {total_token}, Accuracy: {right_token / total_token:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Fscore: {fscore:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic.id2token = {v: k for k, v in word_dic.token2id.items()}\n",
    "char_dic.id2token = {v: k for k, v in char_dic.token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3081 [00:00<03:24, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Predict Check==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3081/3081 [02:59<00:00, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 29526, Correct: 24403, Pred: 31515\n",
      "Right: 849610.0, Total: 867613.0, Accuracy: 0.9792\n",
      "Precision: 0.7743296842773283, Recall: 0.8264919054392739, Fscore: 0.7995609508363233\n"
     ]
    }
   ],
   "source": [
    "################ valid predict check #####################\n",
    "print(\"============== Predict Check==========\")\n",
    "batch_size = 10\n",
    "true_seqs, pred_seqs, word_seqs, char_seqs = [], [], [], []\n",
    "right_token, total_token = 0, 0\n",
    "batch_steps = len(valid_word_documents) // batch_size + 1\n",
    "random_ids = list(range(len(valid_word_documents)))\n",
    "seq_model.eval()\n",
    "for batch_i in tqdm(range(batch_steps)):\n",
    "    batch_ids = random_ids[batch_i * batch_size: (batch_i + 1) * batch_size]\n",
    "    batch_word_documents = [valid_word_documents[i] for i in batch_ids]\n",
    "    batch_label_documents = [valid_label_documents[i] for i in batch_ids]\n",
    "\n",
    "    valid_word_features = get_word_features(batch_word_documents, word_dic, config_dic.get(\"gpu\"))\n",
    "    valid_char_features = get_char_features(batch_word_documents, char_dic, config_dic.get(\"gpu\"))\n",
    "    if config_dic.get(\"sp_path\"):\n",
    "        valid_sw_features = get_sw_features(batch_word_documents, sw_dic, sp, config_dic.get(\"gpu\"))\n",
    "    else:\n",
    "        valid_sw_features = None\n",
    "    valid_label_features = get_label_features(batch_label_documents, label_dic, config_dic.get(\"gpu\"))\n",
    "    valid_tag_seq = seq_model.forward(valid_word_features, valid_char_features, valid_sw_features)\n",
    "    rt, tt = predict_check(valid_tag_seq, valid_label_features.get(\"label_ids\"), valid_word_features.get(\"masks\"))\n",
    "    right_token += rt\n",
    "    total_token += tt\n",
    "    ################ evaluate by precision, recall and fscore ###################\n",
    "    masks = valid_word_features.get(\"masks\")\n",
    "    word_seqs.extend([word_dic.id2token.get(int(word_id)) for word_id in valid_word_features.get(\"word_ids\").masked_select(masks)])\n",
    "    \n",
    "#     char_ids = valid_char_features.get(\"char_ids\")\n",
    "#     char_masks = masks.unsqueeze(-1).expand(char_ids.shape)\n",
    "#     chars = []\n",
    "#     for i, char_id in enumerate(char_ids.masked_select(char_masks)):\n",
    "#         if i != 0 and i % char_ids.shape[-1] == 0:\n",
    "#             char_seqs.append(chars)\n",
    "#             chars = []\n",
    "#         if not char_id == char_dic.token2id[PADDING]:\n",
    "#             chars.append(char_dic.id2token.get(int(char_id)))\n",
    "#     char_seqs.append(chars)\n",
    "    \n",
    "    true_seqs.extend([label_dic.id2token[int(label_id)] for label_id in valid_label_features.get(\"label_ids\").masked_select(masks)])\n",
    "    pred_seqs.extend([label_dic.id2token[int(label_id)] for label_id in valid_tag_seq.masked_select(masks)])\n",
    "    \n",
    "precision, recall, fscore = evaluate(true_seqs, pred_seqs)\n",
    "print(f\"Right: {right_token}, Total: {total_token}, Accuracy: {right_token / total_token:.4f}\")\n",
    "print(f\"Precision: {precision}, Recall: {recall}, Fscore: {fscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate by entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_entities = []\n",
    "true_entity = \"\"\n",
    "for i, (word, label) in enumerate(zip(word_seqs, true_seqs)):\n",
    "    if label == \"O\":\n",
    "        pass\n",
    "    elif label == \"B-CHEM\" and not true_entity:\n",
    "        true_entity += word\n",
    "    elif label == \"I-CHEM\" and true_entity:\n",
    "        true_entity += (\" \" + word)\n",
    "    elif label == \"E-CHEM\" and true_entity:\n",
    "        true_entity += (\" \" + word)\n",
    "        true_entities.append(true_entity)\n",
    "        true_entity = \"\"\n",
    "    elif label == \"S-CHEM\":\n",
    "        true_entities.append(word)\n",
    "        true_entity = \"\"\n",
    "    else:\n",
    "        # ありえないやつも考えなくてはいけない。\n",
    "        print(\"Warning!! The combination of the labels is not compatible.\")\n",
    "        true_entity = \"\"\n",
    "    pre_label = label\n",
    "true_entity_counter = Counter(true_entities)\n",
    "\n",
    "pred_entities = []\n",
    "pred_entity = \"\"\n",
    "for i, (word, label) in enumerate(zip(word_seqs, pred_seqs)):\n",
    "    if label == \"O\":\n",
    "        pass\n",
    "    elif label == \"B-CHEM\" and not pred_entity:\n",
    "        pred_entity += word\n",
    "    elif label == \"I-CHEM\" and pred_entity:\n",
    "        pred_entity += (\" \" + word)\n",
    "    elif label == \"E-CHEM\" and pred_entity:\n",
    "        pred_entity += (\" \" + word)\n",
    "        pred_entities.append(pred_entity)\n",
    "        pred_entity = \"\"\n",
    "    elif label == \"S-CHEM\":\n",
    "        pred_entities.append(word)\n",
    "        pred_entity = \"\"\n",
    "    else:\n",
    "        # ありえないやつも考えなくてはいけない。\n",
    "        print(\"Warning!! The combination of the labels is not compatible.\")\n",
    "        pred_entity = \"\"\n",
    "    pre_label = label\n",
    "pred_entity_counter = Counter(pred_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"entity\": [], \"true_count\": [], \"pred_count\": [], \"tp\": [], \"fp\": [], \"fn\": []}\n",
    "for entity in set(true_entities) | set(pred_entities):\n",
    "    pred_count = pred_entity_counter.get(entity, 0)\n",
    "    true_count = true_entity_counter.get(entity, 0)\n",
    "    results[\"entity\"].append(entity)\n",
    "    results[\"true_count\"].append(true_count)\n",
    "    results[\"pred_count\"].append(pred_count)\n",
    "    results[\"tp\"].append(min(true_count, pred_count))\n",
    "    results[\"fp\"].append(max(true_count - pred_count, 0))\n",
    "    results[\"fn\"].append(max(pred_count - true_count, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results).sort_values(\"true_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>true_count</th>\n",
       "      <th>pred_count</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>Steroid</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>diallyl disulfide</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>polyesters</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>quinpirole</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>telmisartan</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>NaB</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>carbonate</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10444</th>\n",
       "      <td>ZnS</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>Cort</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>MAs</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10439</th>\n",
       "      <td>isoflavonoid</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>pyrido [ 0,0 - d ] pyrimidines</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10435</th>\n",
       "      <td>PEG 0000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0 - OH - BP - 0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>CoA</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>0 - OH</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>DEP</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>ifenprodil</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10424</th>\n",
       "      <td>DM0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>suramin</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>crocin</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>FeS</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>riboflavin</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Arsenic trioxide</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>CN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>nitrotyrosine</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>dileucine</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>betulinic acid</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>In ( x ) Ga ( 0 - x ) As</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>C ( 00 ) φ ( 0 ) C ( 00 )</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>taggants</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>T and - 000C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>hydroxyethylcellulose</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>chemotype</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>PP0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>GKAs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>nebulized</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>PEG - b - P [ Asp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>00 - trans</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>HMG - coA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>GCE</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>[ Rh ( 0 )</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Atractylodis Macrocephalae</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>bridged</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>Cretan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>S - F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>cannabinoid</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>catharinensis</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>methoxylated</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>amylin</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Ru ( bpy ) 0 ( &lt;/unk&gt; ) ]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>poly ( alkyl - 0 - cyanoacrylate ) [ PACA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>butyl lucidenate P ( 0 )</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>phytosteryl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>0 - hydroxy - 0 - nonenal ( + )</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>substituting</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>cisplatin : ( i )</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>Phellodendron amurensis</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>calcium ionophore</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          entity  true_count  pred_count  tp  \\\n",
       "4054                                     Steroid           4           3   3   \n",
       "8591                           diallyl disulfide           4           4   4   \n",
       "3350                                  polyesters           4           0   0   \n",
       "4275                                  quinpirole           4           4   4   \n",
       "8192                                 telmisartan           4           4   4   \n",
       "4895                                         NaB           4           4   4   \n",
       "949                                    carbonate           4           4   4   \n",
       "10444                                        ZnS           4           4   4   \n",
       "4059                                        Cort           4           1   1   \n",
       "2394                                         MAs           4           0   0   \n",
       "10439                               isoflavonoid           4           4   4   \n",
       "1573              pyrido [ 0,0 - d ] pyrimidines           4           4   4   \n",
       "10435                                   PEG 0000           4           1   1   \n",
       "4891                             0 - OH - BP - 0           4           3   3   \n",
       "259                                          CoA           4           3   3   \n",
       "7166                                      0 - OH           4           4   4   \n",
       "9054                                         DEP           4           0   0   \n",
       "5727                                  ifenprodil           4           4   4   \n",
       "10424                                        DM0           4           0   0   \n",
       "5730                                     suramin           4           4   4   \n",
       "9046                                      crocin           4           4   4   \n",
       "2416                                         FeS           4           0   0   \n",
       "6708                                  riboflavin           4           4   4   \n",
       "245                             Arsenic trioxide           4           4   4   \n",
       "1550                                          CN           4           1   1   \n",
       "6701                               nitrotyrosine           4           3   3   \n",
       "944                                    dileucine           4           0   0   \n",
       "5716                              betulinic acid           4           3   3   \n",
       "4007                    In ( x ) Ga ( 0 - x ) As           4           0   0   \n",
       "1651                   C ( 00 ) φ ( 0 ) C ( 00 )           4           0   0   \n",
       "...                                          ...         ...         ...  ..   \n",
       "8153                                    taggants           0           1   0   \n",
       "8152                                T and - 000C           0           1   0   \n",
       "8108                       hydroxyethylcellulose           0           3   0   \n",
       "8109                                   chemotype           0           1   0   \n",
       "3441                                         PP0           0          13   0   \n",
       "3440                                        GKAs           0           1   0   \n",
       "8112                                   nebulized           0           1   0   \n",
       "8114                           PEG - b - P [ Asp           0           1   0   \n",
       "3436                                  00 - trans           0           1   0   \n",
       "3431                                   HMG - coA           0           1   0   \n",
       "8119                                         GCE           0           2   0   \n",
       "8120                                          Tx           0           3   0   \n",
       "3425                                  [ Rh ( 0 )           0           1   0   \n",
       "3423                  Atractylodis Macrocephalae           0           1   0   \n",
       "3420                                     bridged           0           1   0   \n",
       "8128                                      Cretan           0           2   0   \n",
       "8129                                       S - F           0           1   0   \n",
       "8131                                 cannabinoid           0          13   0   \n",
       "8132                               catharinensis           0           2   0   \n",
       "3414                                methoxylated           0           1   0   \n",
       "3410                                      amylin           0          24   0   \n",
       "8138                   Ru ( bpy ) 0 ( </unk> ) ]           0           1   0   \n",
       "3406   poly ( alkyl - 0 - cyanoacrylate ) [ PACA           0           1   0   \n",
       "8142                    butyl lucidenate P ( 0 )           0           1   0   \n",
       "3394                                 phytosteryl           0           1   0   \n",
       "8146             0 - hydroxy - 0 - nonenal ( + )           0           1   0   \n",
       "8147                                substituting           0           1   0   \n",
       "8149                           cisplatin : ( i )           0           1   0   \n",
       "8150                     Phellodendron amurensis           0           1   0   \n",
       "11367                          calcium ionophore           0           2   0   \n",
       "\n",
       "       fp  fn  \n",
       "4054    1   0  \n",
       "8591    0   0  \n",
       "3350    4   0  \n",
       "4275    0   0  \n",
       "8192    0   0  \n",
       "4895    0   0  \n",
       "949     0   0  \n",
       "10444   0   0  \n",
       "4059    3   0  \n",
       "2394    4   0  \n",
       "10439   0   0  \n",
       "1573    0   0  \n",
       "10435   3   0  \n",
       "4891    1   0  \n",
       "259     1   0  \n",
       "7166    0   0  \n",
       "9054    4   0  \n",
       "5727    0   0  \n",
       "10424   4   0  \n",
       "5730    0   0  \n",
       "9046    0   0  \n",
       "2416    4   0  \n",
       "6708    0   0  \n",
       "245     0   0  \n",
       "1550    3   0  \n",
       "6701    1   0  \n",
       "944     4   0  \n",
       "5716    1   0  \n",
       "4007    4   0  \n",
       "1651    4   0  \n",
       "...    ..  ..  \n",
       "8153    0   1  \n",
       "8152    0   1  \n",
       "8108    0   3  \n",
       "8109    0   1  \n",
       "3441    0  13  \n",
       "3440    0   1  \n",
       "8112    0   1  \n",
       "8114    0   1  \n",
       "3436    0   1  \n",
       "3431    0   1  \n",
       "8119    0   2  \n",
       "8120    0   3  \n",
       "3425    0   1  \n",
       "3423    0   1  \n",
       "3420    0   1  \n",
       "8128    0   2  \n",
       "8129    0   1  \n",
       "8131    0  13  \n",
       "8132    0   2  \n",
       "3414    0   1  \n",
       "3410    0  24  \n",
       "8138    0   1  \n",
       "3406    0   1  \n",
       "8142    0   1  \n",
       "3394    0   1  \n",
       "8146    0   1  \n",
       "8147    0   1  \n",
       "8149    0   1  \n",
       "8150    0   1  \n",
       "11367   0   2  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
