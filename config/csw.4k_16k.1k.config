### NER ###
train_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/train.bioes
dev_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/valid.bioes
test_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/test.bioes
model_dir=/home/sekine/SubwordSequenceLabeling/Repository/NERModel/csw4k_16k.lm1k

### LanguageModel ###
lm_dir=/home/sekine/SubwordSequenceLabeling/Repository/LargeCorpus/large_corpus_1k.txt
pretrain_model_dir=/home/sekine/SubwordSequenceLabeling/Repository/LanguageModel/csw4k_16k.lm1k

### Share ###
word_emb_dir=/home/sekine/SubwordSequenceLabeling/Repository/GloVe/gv.d50

### Model ###
sw_num=2
sentence_piece_dirs=[/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp4000.model,/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp16000.model]
word_emb_dim=50
char_emb_dim=30
sw_emb_dim=50
char_hidden_dim=50
sw_hidden_dim=50
hidden_dim=100
dropout=0.5
lstm_layer=1
bilstm=True
lr=0.005
lr_decay=0.0001
momentum=0
l2=0.0000001
gpu=True
clip=5.0

### Train ###
ner_epoch=100
lm_epoch=5
lm_vocab_min_count=5
batch_size=10
norm_word_emb=False
norm_char_emb=False
number_normalized=True
cammel_normalized=True
optimizer=SGD
ave_batch_loss=False
