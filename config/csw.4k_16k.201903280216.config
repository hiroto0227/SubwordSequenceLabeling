### NER ###
train_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/train.bioes
dev_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/valid.bioes
test_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/test.bioes
model_dir=/home/sekine/SubwordSequenceLabeling/Repository/NERModel/csw4k_16k.lm50k

### LanguageModel ###
lm_dir=/home/sekine/SubwordSequenceLabeling/Repository/LargeCorpus/large_corpus_50k.txt
pretrain_model_dir=/home/sekine/SubwordSequenceLabeling/Repository/LanguageModel/csw4k_16k.lm50k

### Share ###
word_emb_dir=/home/sekine/SubwordSequenceLabeling/Repository/GloVe/gv.d50

### Model ###
sw_num=2
sentence_piece_dirs=[/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp4000.model,/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp16000.model]
word_emb_dim=50
char_emb_dim=30
sw_emb_dim=50
char_hidden_dim=50
sw_hidden_dim=50
hidden_dim=200
dropout=0.5
lstm_layer=1
bilstm=True
lr=0.005
lr_decay=0.0001
momentum=0
l2=0.00000001
gpu=True
clip=5.0

### NER Train ###
ner_epoch=50
lm_epoch=1
lm_vocab_min_count=10
batch_size=10
norm_word_emb=False
norm_char_emb=False
number_normalized=True
cammel_normalized=True
optimizer=SGD
ave_batch_loss=False
