train_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/short.bioes
dev_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/short.bioes
test_dir=/home/sekine/SubwordSequenceLabeling/Repository/Chemdner/short.bioes
model_dir=/home/sekine/SubwordSequenceLabeling/Repository/NERModel/csw4k_16k
lm_dir=/home/sekine/SubwordSequenceLabeling/Repository/LargeCorpus/short_corpus.txt
pretrain_model_dir=/home/sekine/SubwordSequenceLabeling/Repository/LanguageModel/csw4k_16k
word_emb_dir=/home/sekine/SubwordSequenceLabeling/Repository/GloVe/gv.d50

sw_num=2
sentence_piece_dirs=[/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp4000.model,/home/sekine/SubwordSequenceLabeling/Repository/SentencePiece/sp16000.model]

norm_word_emb=False
norm_char_emb=False
number_normalized=True
cammel_normalized=True
word_emb_dim=50
char_emb_dim=30
sw_emb_dim=50

###TrainingSetting###
optimizer=SGD
iteration=1
batch_size=100
ave_batch_loss=False

###Hyperparameters###
char_hidden_dim=50
sw_hidden_dim=50
hidden_dim=100
dropout=0.5
lstm_layer=1
bilstm=True
learning_rate=0.005
lr_decay=0.0001
momentum=0
l2=1e-8
gpu=False
clip=5.0
