{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gensim\n",
    "import sys\n",
    "from itertools import chain\n",
    "sys.path.append(\"./ner\")\n",
    "from lib.function import tokenize\n",
    "from languagemodel.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from chem_sentencepiece import chem_sentencepiece\n",
    "\n",
    "# lm data load\n",
    "with open(\"./Repository/LargeCorpus/large_corpus_1k.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    datas = f.read().split(\"\\n\")\n",
    "\n",
    "# build_alphabet\n",
    "word_documents = [[word for word in tokenize(document)] for document in datas] # Document数 x 単語数 x re.splitの速度\n",
    "word_dic = Dictionary(word_documents)\n",
    "\n",
    "sp = chem_sentencepiece.ChemSentencePiece()\n",
    "sp.load(sp_path=\"./Repository/SentencePiece/sp4000.model\")\n",
    "\n",
    "sw4k_documents = []\n",
    "for word_document in word_documents:\n",
    "    sws = [sp.tokenize(word) for word in word_document]\n",
    "    sw4k_documents.append(list(chain.from_iterable(sws)))\n",
    "sw4k_dic = Dictionary(sw4k_documents)\n",
    "\n",
    "char_documents = [[char for char in document] for document in datas] # Document数 x 文字数\n",
    "char_dic = Dictionary(char_documents)\n",
    "\n",
    "# idnize\n",
    "# batchify(padding)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmasks(sw_documents):\n",
    "    f_masks = []\n",
    "    for sw_document in sw_documents:\n",
    "        f_mask = [0 for i in range(len(sw_document))]\n",
    "        for i, sw in enumerate(sw_document):\n",
    "            if sw.startswith(\"▁\"):\n",
    "                f_mask[i] = 1\n",
    "        f_masks.append(f_mask)\n",
    "    return f_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bmasks(sw_documents):\n",
    "    b_masks = []\n",
    "    for sw_document in sw_documents:\n",
    "        is_pre_first = True\n",
    "        b_mask = [0 for i in range(len(sw_document))]\n",
    "        for i, sw in enumerate(sw_document[::-1]):\n",
    "            if is_pre_first:\n",
    "                b_mask[i] = 1\n",
    "            is_pre_first = sw.startswith(\"▁\")\n",
    "        b_masks.append(b_mask[::-1])\n",
    "    return b_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------The-----------\n",
      "▁The\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------------------\n",
      "▁-\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------is-----------\n",
      "▁is\n",
      "-------essential-----------\n",
      "▁essential\n",
      "-------for-----------\n",
      "▁for\n",
      "-------the-----------\n",
      "▁the\n",
      "-------replication-----------\n",
      "▁replication\n",
      "-------of-----------\n",
      "▁of\n",
      "-------dengue-----------\n",
      "▁d\n",
      "eng\n",
      "ue\n",
      "-------virus-----------\n",
      "▁virus\n",
      "-------,-----------\n",
      "▁,\n",
      "-------which-----------\n",
      "▁which\n",
      "-------is-----------\n",
      "▁is\n",
      "-------the-----------\n",
      "▁the\n",
      "-------etiologic-----------\n",
      "▁et\n",
      "i\n",
      "ologic\n",
      "-------agent-----------\n",
      "▁agent\n",
      "-------of-----------\n",
      "▁of\n",
      "-------dengue-----------\n",
      "▁d\n",
      "eng\n",
      "ue\n",
      "-------and-----------\n",
      "▁and\n",
      "-------hemorrhagic-----------\n",
      "▁hemo\n",
      "r\n",
      "rh\n",
      "ag\n",
      "ic\n",
      "-------fevers-----------\n",
      "▁fe\n",
      "ver\n",
      "s\n",
      "-------,-----------\n",
      "▁,\n",
      "-------diseases-----------\n",
      "▁diseases\n",
      "-------that-----------\n",
      "▁that\n",
      "-------are-----------\n",
      "▁are\n",
      "-------a-----------\n",
      "▁a\n",
      "-------burden-----------\n",
      "▁b\n",
      "ur\n",
      "d\n",
      "en\n",
      "-------for-----------\n",
      "▁for\n",
      "-------the-----------\n",
      "▁the\n",
      "-------tropical-----------\n",
      "▁\n",
      "trop\n",
      "ical\n",
      "-------and-----------\n",
      "▁and\n",
      "-------subtropical-----------\n",
      "▁sub\n",
      "trop\n",
      "ical\n",
      "-------areas-----------\n",
      "▁area\n",
      "s\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------world-----------\n",
      "▁world\n",
      "-------.-----------\n",
      "▁.\n",
      "-------The-----------\n",
      "▁The\n",
      "-------active-----------\n",
      "▁active\n",
      "-------form-----------\n",
      "▁form\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------linked-----------\n",
      "▁linked\n",
      "-------to-----------\n",
      "▁to\n",
      "-------the-----------\n",
      "▁the\n",
      "-------40-----------\n",
      "▁40\n",
      "-------residues-----------\n",
      "▁residues\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------cofactor-----------\n",
      "▁co\n",
      "factor\n",
      "-------shows-----------\n",
      "▁shows\n",
      "-------highly-----------\n",
      "▁highly\n",
      "-------flexible-----------\n",
      "▁flexible\n",
      "-------and-----------\n",
      "▁and\n",
      "-------disordered-----------\n",
      "▁disorder\n",
      "ed\n",
      "-------region-----------\n",
      "▁region\n",
      "-------(-----------\n",
      "▁(\n",
      "-------s-----------\n",
      "▁s\n",
      "-------)-----------\n",
      "▁)\n",
      "-------that-----------\n",
      "▁that\n",
      "-------are-----------\n",
      "▁are\n",
      "-------responsible-----------\n",
      "▁responsible\n",
      "-------for-----------\n",
      "▁for\n",
      "-------its-----------\n",
      "▁its\n",
      "-------high-----------\n",
      "▁high\n",
      "-------propensity-----------\n",
      "▁\n",
      "prop\n",
      "ens\n",
      "ity\n",
      "-------to-----------\n",
      "▁to\n",
      "-------aggregate-----------\n",
      "▁a\n",
      "g\n",
      "g\n",
      "reg\n",
      "ate\n",
      "-------at-----------\n",
      "▁at\n",
      "-------the-----------\n",
      "▁the\n",
      "-------concentrations-----------\n",
      "▁concentrations\n",
      "-------necessary-----------\n",
      "▁necessary\n",
      "-------for-----------\n",
      "▁for\n",
      "-------NMR-----------\n",
      "▁NMR\n",
      "-------spectroscopy-----------\n",
      "▁spectroscopy\n",
      "-------studies-----------\n",
      "▁studies\n",
      "-------or-----------\n",
      "▁or\n",
      "-------for-----------\n",
      "▁for\n",
      "-------crystallization-----------\n",
      "▁crystal\n",
      "l\n",
      "ization\n",
      "-------.-----------\n",
      "▁.\n",
      "-------Limited-----------\n",
      "▁Li\n",
      "mit\n",
      "ed\n",
      "-------proteolysis-----------\n",
      "▁proteolysis\n",
      "-------of-----------\n",
      "▁of\n",
      "-------this-----------\n",
      "▁this\n",
      "-------active-----------\n",
      "▁active\n",
      "-------form-----------\n",
      "▁form\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------enabled-----------\n",
      "▁enable\n",
      "d\n",
      "-------us-----------\n",
      "▁\n",
      "us\n",
      "-------to-----------\n",
      "▁to\n",
      "-------obtain-----------\n",
      "▁obtain\n",
      "-------a-----------\n",
      "▁a\n",
      "-------folded-----------\n",
      "▁\n",
      "fold\n",
      "ed\n",
      "-------and-----------\n",
      "▁and\n",
      "-------new-----------\n",
      "▁new\n",
      "-------essential-----------\n",
      "▁essential\n",
      "-------form-----------\n",
      "▁form\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------------------\n",
      "▁-\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------.-----------\n",
      "▁.\n",
      "-------We-----------\n",
      "▁We\n",
      "-------found-----------\n",
      "▁found\n",
      "-------that-----------\n",
      "▁that\n",
      "-------the-----------\n",
      "▁the\n",
      "-------region-----------\n",
      "▁region\n",
      "-------from-----------\n",
      "▁from\n",
      "-------residues-----------\n",
      "▁residues\n",
      "-------D-----------\n",
      "▁D\n",
      "-------50-----------\n",
      "▁50\n",
      "-------to-----------\n",
      "▁to\n",
      "-------E-----------\n",
      "▁E\n",
      "-------80-----------\n",
      "▁\n",
      "80\n",
      "-------of-----------\n",
      "▁of\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------interacts-----------\n",
      "▁interact\n",
      "s\n",
      "-------directly-----------\n",
      "▁directly\n",
      "-------and-----------\n",
      "▁and\n",
      "-------strongly-----------\n",
      "▁strongly\n",
      "-------with-----------\n",
      "▁with\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------domain-----------\n",
      "▁domain\n",
      "-------.-----------\n",
      "▁.\n",
      "-------The-----------\n",
      "▁The\n",
      "-------proteolytic-----------\n",
      "▁proteolytic\n",
      "-------activity-----------\n",
      "▁activity\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------noncovalently-----------\n",
      "▁non\n",
      "co\n",
      "valent\n",
      "ly\n",
      "-------binding-----------\n",
      "▁binding\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------was-----------\n",
      "▁was\n",
      "-------determined-----------\n",
      "▁determined\n",
      "-------by-----------\n",
      "▁by\n",
      "-------a-----------\n",
      "▁a\n",
      "-------rapid-----------\n",
      "▁rapid\n",
      "-------and-----------\n",
      "▁and\n",
      "-------continuous-----------\n",
      "▁continuous\n",
      "-------fluorescence-----------\n",
      "▁fluorescence\n",
      "-------resonance-----------\n",
      "▁resonance\n",
      "-------energy-----------\n",
      "▁energy\n",
      "-------transfer-----------\n",
      "▁transfer\n",
      "-------activity-----------\n",
      "▁activity\n",
      "-------assay-----------\n",
      "▁assay\n",
      "-------using-----------\n",
      "▁using\n",
      "-------a-----------\n",
      "▁a\n",
      "-------depsipeptide-----------\n",
      "▁de\n",
      "p\n",
      "s\n",
      "i\n",
      "peptide\n",
      "-------substrate-----------\n",
      "▁substrate\n",
      "-------.-----------\n",
      "▁.\n",
      "-------The-----------\n",
      "▁The\n",
      "-------new-----------\n",
      "▁new\n",
      "-------protein-----------\n",
      "▁protein\n",
      "-------------------\n",
      "▁-\n",
      "-------cofactor-----------\n",
      "▁co\n",
      "factor\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------obtained-----------\n",
      "▁obtained\n",
      "-------,-----------\n",
      "▁,\n",
      "-------encompassing-----------\n",
      "▁en\n",
      "comp\n",
      "as\n",
      "s\n",
      "ing\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------fragment-----------\n",
      "▁fragment\n",
      "-------(-----------\n",
      "▁(\n",
      "-------D-----------\n",
      "▁D\n",
      "-------50-----------\n",
      "▁50\n",
      "-------------------\n",
      "▁-\n",
      "-------E-----------\n",
      "▁E\n",
      "-------80-----------\n",
      "▁\n",
      "80\n",
      "-------)-----------\n",
      "▁)\n",
      "-------and-----------\n",
      "▁and\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------protease-----------\n",
      "▁protease\n",
      "-------,-----------\n",
      "▁,\n",
      "-------shows-----------\n",
      "▁shows\n",
      "-------proteolytic-----------\n",
      "▁proteolytic\n",
      "-------activity-----------\n",
      "▁activity\n",
      "-------.-----------\n",
      "▁.\n",
      "-------The-----------\n",
      "▁The\n",
      "-------(-----------\n",
      "▁(\n",
      "-------1-----------\n",
      "▁1\n",
      "-------)-----------\n",
      "▁)\n",
      "-------H-----------\n",
      "▁H\n",
      "-------------------\n",
      "▁-\n",
      "-------(-----------\n",
      "▁(\n",
      "-------15-----------\n",
      "▁15\n",
      "-------)-----------\n",
      "▁)\n",
      "-------N-----------\n",
      "▁N\n",
      "-------------------\n",
      "▁-\n",
      "-------heteronuclear-----------\n",
      "▁hetero\n",
      "nuclear\n",
      "-------single-----------\n",
      "▁single\n",
      "-------quantum-----------\n",
      "▁quantum\n",
      "-------coherence-----------\n",
      "▁co\n",
      "her\n",
      "ence\n",
      "-------spectrum-----------\n",
      "▁spectrum\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------isotopically-----------\n",
      "▁iso\n",
      "topic\n",
      "ally\n",
      "-------enriched-----------\n",
      "▁en\n",
      "rich\n",
      "ed\n",
      "-------protein-----------\n",
      "▁protein\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------shows-----------\n",
      "▁shows\n",
      "-------good-----------\n",
      "▁good\n",
      "-------cross-----------\n",
      "▁cross\n",
      "-------------------\n",
      "▁-\n",
      "-------peak-----------\n",
      "▁peak\n",
      "-------dispersion-----------\n",
      "▁dispersion\n",
      "-------;-----------\n",
      "▁;\n",
      "-------this-----------\n",
      "▁this\n",
      "-------is-----------\n",
      "▁is\n",
      "-------indicative-----------\n",
      "▁indicati\n",
      "ve\n",
      "-------of-----------\n",
      "▁of\n",
      "-------a-----------\n",
      "▁a\n",
      "-------stable-----------\n",
      "▁stable\n",
      "-------folded-----------\n",
      "▁\n",
      "fold\n",
      "ed\n",
      "-------state-----------\n",
      "▁state\n",
      "-------.-----------\n",
      "▁.\n",
      "-------Our-----------\n",
      "▁Our\n",
      "-------results-----------\n",
      "▁results\n",
      "-------significantly-----------\n",
      "▁significantly\n",
      "-------complement-----------\n",
      "▁complement\n",
      "-------the-----------\n",
      "▁the\n",
      "-------X-----------\n",
      "▁X\n",
      "-------------------\n",
      "▁-\n",
      "-------ray-----------\n",
      "▁\n",
      "ray\n",
      "-------structure-----------\n",
      "▁structure\n",
      "-------of-----------\n",
      "▁of\n",
      "-------the-----------\n",
      "▁the\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------------------\n",
      "▁-\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------pro-----------\n",
      "▁pro\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------published-----------\n",
      "▁published\n",
      "-------recently-----------\n",
      "▁recently\n",
      "-------.-----------\n",
      "▁.\n",
      "-------Moreover-----------\n",
      "▁Moreover\n",
      "-------,-----------\n",
      "▁,\n",
      "-------these-----------\n",
      "▁these\n",
      "-------results-----------\n",
      "▁results\n",
      "-------open-----------\n",
      "▁open\n",
      "-------the-----------\n",
      "▁the\n",
      "-------way-----------\n",
      "▁way\n",
      "-------to-----------\n",
      "▁to\n",
      "-------performing-----------\n",
      "▁per\n",
      "form\n",
      "ing\n",
      "-------direct-----------\n",
      "▁direct\n",
      "-------structural-----------\n",
      "▁structural\n",
      "-------and-----------\n",
      "▁and\n",
      "-------interaction-----------\n",
      "▁interaction\n",
      "-------studies-----------\n",
      "▁studies\n",
      "-------in-----------\n",
      "▁in\n",
      "-------solution-----------\n",
      "▁solution\n",
      "-------on-----------\n",
      "▁on\n",
      "-------a-----------\n",
      "▁a\n",
      "-------new-----------\n",
      "▁new\n",
      "-------active-----------\n",
      "▁active\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------2-----------\n",
      "▁2\n",
      "-------B-----------\n",
      "▁B\n",
      "-------------------\n",
      "▁-\n",
      "-------NS-----------\n",
      "▁N\n",
      "S\n",
      "-------3-----------\n",
      "▁3\n",
      "-------pro-----------\n",
      "▁pro\n",
      "-------complex-----------\n",
      "▁complex\n",
      "-------with-----------\n",
      "▁with\n",
      "-------libraries-----------\n",
      "▁l\n",
      "ib\n",
      "ra\n",
      "ries\n",
      "-------of-----------\n",
      "▁of\n",
      "-------substrates-----------\n",
      "▁substrates\n",
      "-------and-----------\n",
      "▁and\n",
      "-------inhibitors-----------\n",
      "▁inhibitors\n",
      "-------in-----------\n",
      "▁in\n",
      "-------order-----------\n",
      "▁order\n",
      "-------to-----------\n",
      "▁to\n",
      "-------identify-----------\n",
      "▁identify\n",
      "-------new-----------\n",
      "▁new\n",
      "-------drugs-----------\n",
      "▁drugs\n",
      "-------that-----------\n",
      "▁that\n",
      "-------prevent-----------\n",
      "▁prevent\n",
      "-------viral-----------\n",
      "▁viral\n",
      "-------polyprotein-----------\n",
      "▁poly\n",
      "protein\n",
      "-------processing-----------\n",
      "▁processing\n",
      "-------.-----------\n",
      "▁.\n"
     ]
    }
   ],
   "source": [
    "mask = []\n",
    "for word in word_documents[0]:\n",
    "    print(f\"-------{word}-----------\")\n",
    "    for sw in sp.tokenize(word, B_TAG=True):\n",
    "        print(sw)\n",
    "        if sw.startswith(\"▁\"):\n",
    "            mask.append(1)\n",
    "        else:\n",
    "            mask.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ▁The\n",
      "1 ▁N\n",
      "0 S\n",
      "1 2\n",
      "1 B\n",
      "1 -\n",
      "1 NS\n",
      "0 3\n",
      "1 ▁protease\n",
      "1 ▁complex\n",
      "1 ▁is\n",
      "1 ▁essential\n",
      "1 ▁for\n",
      "1 ▁the\n",
      "1 ▁replication\n",
      "1 ▁of\n",
      "1 ▁d\n",
      "1 eng\n",
      "0 ue\n",
      "0 ▁virus\n",
      "1 ,\n",
      "1 ▁which\n",
      "1 ▁is\n",
      "1 ▁the\n",
      "1 ▁et\n",
      "1 i\n",
      "0 ologic\n",
      "0 ▁agent\n",
      "1 ▁of\n",
      "1 ▁d\n",
      "1 eng\n",
      "0 ue\n",
      "0 ▁and\n",
      "1 ▁hemo\n",
      "1 r\n",
      "0 rh\n",
      "0 ag\n",
      "0 ic\n",
      "0 ▁fe\n",
      "1 ver\n",
      "0 s\n",
      "0 ,\n",
      "1 ▁diseases\n",
      "1 ▁that\n",
      "1 ▁are\n",
      "1 ▁a\n",
      "1 ▁b\n",
      "1 ur\n",
      "0 d\n",
      "0 en\n",
      "0 ▁for\n",
      "1 ▁the\n",
      "1 ▁\n",
      "1 trop\n",
      "0 ical\n",
      "0 ▁and\n",
      "1 ▁sub\n",
      "1 trop\n",
      "0 ical\n",
      "0 ▁area\n",
      "1 s\n",
      "0 ▁of\n",
      "1 ▁the\n",
      "1 ▁world\n",
      "1 .\n",
      "1 ▁The\n",
      "1 ▁active\n",
      "1 ▁form\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁N\n",
      "1 S\n",
      "0 3\n",
      "1 ▁protease\n",
      "1 ▁linked\n",
      "1 ▁to\n",
      "1 ▁the\n",
      "1 ▁40\n",
      "1 ▁residues\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁N\n",
      "1 S\n",
      "0 2\n",
      "1 B\n",
      "1 ▁co\n",
      "1 factor\n",
      "0 ▁shows\n",
      "1 ▁highly\n",
      "1 ▁flexible\n",
      "1 ▁and\n",
      "1 ▁disorder\n",
      "1 ed\n",
      "0 ▁region\n",
      "1 (\n",
      "1 s\n",
      "1 )\n",
      "1 ▁that\n",
      "1 ▁are\n",
      "1 ▁responsible\n",
      "1 ▁for\n",
      "1 ▁its\n",
      "1 ▁high\n",
      "1 ▁\n",
      "1 prop\n",
      "0 ens\n",
      "0 ity\n",
      "0 ▁to\n",
      "1 ▁a\n",
      "1 g\n",
      "0 g\n",
      "0 reg\n",
      "0 ate\n",
      "0 ▁at\n",
      "1 ▁the\n",
      "1 ▁concentrations\n",
      "1 ▁necessary\n",
      "1 ▁for\n",
      "1 ▁NMR\n",
      "1 ▁spectroscopy\n",
      "1 ▁studies\n",
      "1 ▁or\n",
      "1 ▁for\n",
      "1 ▁crystal\n",
      "1 l\n",
      "0 ization\n",
      "0 .\n",
      "1 ▁Li\n",
      "1 mit\n",
      "0 ed\n",
      "0 ▁proteolysis\n",
      "1 ▁of\n",
      "1 ▁this\n",
      "1 ▁active\n",
      "1 ▁form\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁protease\n",
      "1 ▁enable\n",
      "1 d\n",
      "0 ▁\n",
      "1 us\n",
      "0 ▁to\n",
      "1 ▁obtain\n",
      "1 ▁a\n",
      "1 ▁\n",
      "1 fold\n",
      "0 ed\n",
      "0 ▁and\n",
      "1 ▁new\n",
      "1 ▁essential\n",
      "1 ▁form\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁N\n",
      "1 S\n",
      "0 2\n",
      "1 B\n",
      "1 -\n",
      "1 NS\n",
      "1 3\n",
      "0 ▁protease\n",
      "1 ▁complex\n",
      "1 .\n",
      "1 ▁We\n",
      "1 ▁found\n",
      "1 ▁that\n",
      "1 ▁the\n",
      "1 ▁region\n",
      "1 ▁from\n",
      "1 ▁residues\n",
      "1 ▁D\n",
      "1 50\n",
      "1 ▁to\n",
      "1 ▁E\n",
      "1 80\n",
      "1 ▁of\n",
      "1 ▁N\n",
      "0 S\n",
      "1 2\n",
      "1 B\n",
      "0 ▁interact\n",
      "1 s\n",
      "1 ▁directly\n",
      "1 ▁and\n",
      "0 ▁strongly\n",
      "1 ▁with\n",
      "1 ▁the\n",
      "1 ▁N\n",
      "1 S\n",
      "1 3\n",
      "1 ▁protease\n",
      "0 ▁domain\n",
      "1 .\n",
      "1 ▁The\n",
      "1 ▁proteolytic\n",
      "1 ▁activity\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁non\n",
      "1 co\n",
      "1 valent\n",
      "1 ly\n",
      "0 ▁binding\n",
      "0 ▁complex\n",
      "0 ▁was\n",
      "1 ▁determined\n",
      "1 ▁by\n",
      "1 ▁a\n",
      "1 ▁rapid\n",
      "1 ▁and\n",
      "1 ▁continuous\n",
      "1 ▁fluorescence\n",
      "1 ▁resonance\n",
      "1 ▁energy\n",
      "1 ▁transfer\n",
      "1 ▁activity\n",
      "1 ▁assay\n",
      "1 ▁using\n",
      "1 ▁a\n",
      "1 ▁de\n",
      "1 p\n",
      "1 s\n",
      "1 i\n",
      "0 peptide\n",
      "0 ▁substrate\n",
      "0 .\n",
      "0 ▁The\n",
      "1 ▁new\n",
      "1 ▁protein\n",
      "1 -\n",
      "1 co\n",
      "1 factor\n",
      "1 ▁complex\n",
      "1 ▁obtained\n",
      "0 ,\n",
      "1 ▁en\n",
      "1 comp\n",
      "1 as\n",
      "1 s\n",
      "0 ing\n",
      "0 ▁the\n",
      "0 ▁N\n",
      "0 S\n",
      "1 2\n",
      "1 B\n",
      "0 ▁fragment\n",
      "1 ▁(\n",
      "1 D\n",
      "1 50\n",
      "1 -\n",
      "1 E\n",
      "1 80\n",
      "1 )\n",
      "1 ▁and\n",
      "1 ▁the\n",
      "0 ▁N\n",
      "1 S\n",
      "1 3\n",
      "1 ▁protease\n",
      "1 ,\n",
      "0 ▁shows\n",
      "1 ▁proteolytic\n",
      "1 ▁activity\n",
      "1 .\n",
      "1 ▁The\n",
      "1 ▁(1)\n",
      "1 H\n",
      "1 -\n",
      "1 (1\n",
      "1 5)\n",
      "1 N\n",
      "1 -\n",
      "1 he\n",
      "1 ter\n",
      "1 o\n",
      "1 nuclear\n",
      "1 ▁single\n",
      "1 ▁quantum\n",
      "1 ▁co\n",
      "1 her\n",
      "0 ence\n",
      "1 ▁spectrum\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "0 ▁iso\n",
      "0 topic\n",
      "1 ally\n",
      "1 ▁en\n",
      "1 rich\n",
      "1 ed\n",
      "0 ▁protein\n",
      "0 ▁complex\n",
      "1 ▁shows\n",
      "0 ▁good\n",
      "0 ▁cross\n",
      "1 -\n",
      "1 pe\n",
      "1 ak\n",
      "1 ▁dispersion\n",
      "1 ;\n",
      "1 ▁this\n",
      "1 ▁is\n",
      "1 ▁indicati\n",
      "1 ve\n",
      "1 ▁of\n",
      "1 ▁a\n",
      "1 ▁stable\n",
      "0 ▁\n",
      "1 fold\n",
      "1 ed\n",
      "1 ▁state\n",
      "1 .\n",
      "0 ▁Our\n",
      "0 ▁results\n",
      "1 ▁significantly\n",
      "1 ▁complement\n",
      "1 ▁the\n",
      "1 ▁X\n",
      "1 -\n",
      "1 ray\n",
      "1 ▁structure\n",
      "1 ▁of\n",
      "1 ▁the\n",
      "1 ▁N\n",
      "0 S\n",
      "1 2\n",
      "1 B\n",
      "1 -\n",
      "1 NS\n",
      "0 3\n",
      "1 pro\n",
      "1 ▁complex\n",
      "1 ▁published\n",
      "1 ▁recently\n",
      "0 .\n",
      "1 ▁Moreover\n",
      "1 ,\n",
      "1 ▁these\n",
      "1 ▁results\n",
      "1 ▁open\n",
      "1 ▁the\n",
      "1 ▁way\n",
      "1 ▁to\n",
      "1 ▁per\n",
      "1 form\n",
      "1 ing\n",
      "1 ▁direct\n",
      "1 ▁structural\n",
      "1 ▁and\n",
      "1 ▁interaction\n",
      "0 ▁studies\n",
      "0 ▁in\n",
      "1 ▁solution\n",
      "1 ▁on\n",
      "1 ▁a\n",
      "1 ▁new\n",
      "1 ▁active\n",
      "1 ▁N\n",
      "1 S\n",
      "1 2\n",
      "1 B\n",
      "1 -\n",
      "1 NS\n",
      "1 3\n",
      "0 pro\n",
      "1 ▁complex\n",
      "1 ▁with\n",
      "1 ▁l\n",
      "1 ib\n",
      "0 ra\n",
      "1 ries\n",
      "1 ▁of\n",
      "1 ▁substrates\n",
      "1 ▁and\n",
      "1 ▁inhibitors\n",
      "0 ▁in\n",
      "0 ▁order\n",
      "0 ▁to\n",
      "1 ▁identify\n",
      "1 ▁new\n",
      "1 ▁drugs\n",
      "1 ▁that\n",
      "1 ▁prevent\n",
      "1 ▁viral\n",
      "1 ▁poly\n",
      "1 protein\n",
      "1 ▁processing\n",
      "1 .\n"
     ]
    }
   ],
   "source": [
    "for m, sw in zip(mask, sw4k_documents[0]):\n",
    "    print(m, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw4k_dic.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
